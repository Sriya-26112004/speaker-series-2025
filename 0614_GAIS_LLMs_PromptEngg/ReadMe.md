# ğŸš€ Global AI Bootcamp â€“ Prompt Engineering with LangChain

ğŸ“… **Date:** 14 June 2025  
ğŸ•™ **Time:** 10:00 AM IST  
ğŸ“ **Location:** Microsoft, Hyderabad   
ğŸ”— **Event Link:** [Register on Meetup](https://www.meetup.com/dot-net-learners-house-hyderabad/events/308109558/?eventOrigin=group_events_list)

**Speaker:** Kajjapu Sriya  
**Topic:** **Introduction to LLMs and Prompt Engineering**  
ğŸ› ï¸ **Live Demo:** LangChain in Action!

 ![GAIS Banner](event banner.png) 

---

### Software/Tools

> 1. OS: Windows 10/11 x64
> 1. Python / .NET 8
> 1. Visual Studio 2022
> 1. Visual Studio Code

### Prior Knowledge

> 1. Programming knowledge in C# / Python

## Technology Stack

> 1. .NET 8, AI, Open AI

---

![Information | 100x100](../Information.png)

---

 ### What are we doing today?
1. Understanding Prompt Engineering
2. What is prompting and why it matters in AI.
3. How prompts guide reasoning and improve accuracy.
4. Real-world use cases with simple examples.

---

![Seatbelt| 100x100](../SeatBelt.png)

---

## ğŸ§  Session Overview

Prompting is the art of crafting clear instructions for AI models using natural language.  
It helps guide the modelâ€™s reasoning, improve accuracy, and ensure structured and relevant responses.

---

# ğŸ¤ Introduction to LLMs & Prompt Engineering

---

## ğŸ”¹ 1. Introduction

- **Transformers** are deep learning models that changed how machines understand human language by focusing on context and meaning through something called attention.
- **LLMs**â€”like GPT-4, Claude, or LLaMAâ€”are AI systems built using transformers, trained on huge datasets, and capable of generating human-like language.
- **Prompt Engineering** is how we talk to these models to get the best resultsâ€”like crafting the perfect question for the smartest assistant in the world

---

## ğŸ”¹ 2. Transformers â€“ The Backbone of AI

### ğŸ§  What is a Transformer?

In 2017, a paper called "*Attention is All You Need*" introduced the Transformer architecture, and it revolutionized NLPâ€”Natural Language Processing.

**Why was it revolutionary?**
- RNNs and LSTMs, older models, processed sentences word-by-word. They were slow and forgot long-term context.
- **Transformers**, in contrast, process all words in parallel and decide what to â€˜pay attentionâ€™ to.

---

### ğŸ” Key Concepts

- **Self-Attention**

  > Example: In â€œThe cat sat on the mat,â€ the word â€œsatâ€ should focus more on â€œcatâ€ than â€œmat.â€ Self-attention helps find that relationship.

- **Multi-Head Attention**

  > Itâ€™s like multiple minds looking at the same sentence from different angles.

- **Positional Encoding**

  > Since words are seen in parallel, we need to give the model a sense of order. Thatâ€™s what positional encoding doesâ€”adds a rhythm or position to each word.

---

### ğŸ¥ Demo Idea
- Highlight how in a sentence, different words relate with varying strengths.
- E.g., show attention weights between â€œsatâ€ and â€œcatâ€ vs â€œsatâ€ and â€œtheâ€.

> Transformers allow models to handle long texts and generate more coherent language. Theyâ€™re the brains behind all modern LLMs.

---

## ğŸ”¹ 3. Large Language Models (LLMs) â€“ Language Generation Engines

### ğŸ’¡ What is an LLM?

LLMs are transformers that have been trained on massive text dataâ€”books, websites, code, Wikipediaâ€”to predict the next word in a sentence.

---

### ğŸ§© Key Ideas

- **Tokenization** â€“ Breaks input into units (like words or subwords).
  
  > â€œChatGPT is coolâ€ â†’ [â€œChatâ€, â€œGâ€, â€œPTâ€, â€œisâ€, â€œcoolâ€]

- **Next Word Prediction** â€“ Given a sentence, whatâ€™s the most probable next word?
- **Fine-Tuning** â€“ Pretrained models can be customized for tasks like legal advice, customer service, etc.

---

### ğŸ¥ Live Demo Idea

1. Use GPT-4 or Azure OpenAI Studio.
2. Try:
    - â€œWrite a haiku about space.â€
    - â€œExplain black holes in 5-year-old language.â€
    - â€œHelp me debug a Python function.â€

> Notice how the same model adapts its tone, language, and depth just based on your request. Thatâ€™s the power of LLMs!

---

## ğŸ”¹ 4. Prompt Engineering â€“ Crafting Better Inputs

### ğŸ› ï¸ What is Prompt Engineering?

Itâ€™s the art of asking questions the right way. The better the prompt, the better the response.

---

### ğŸ“Œ Prompt Styles

- **Zero-shot Prompt**

  > â€œTranslate â€˜Helloâ€™ to French.â€ â†’ â€œBonjourâ€

- **Few-shot Prompt**

  > Give examples:
  > 
  > English â†’ French  
  > Hello â†’ Bonjour  
  > Thank you â†’ Merci  
  > Good night â†’ ?

- **Chain-of-Thought Prompt**

  > â€œIf Alice is taller than Bob, and Bob is taller than Carol, whoâ€™s tallest? Explain step by step.â€

---

### ğŸ¥ Demo (run three versions)

1. **Prompt:**  
   â€œTranslate â€˜Helloâ€™ into Spanish.â€  
   **Output:** â€œHolaâ€

2. **Prompt:**  
   â€œYou are an expert translator. Translate â€˜Helloâ€™ into Spanish and explain your reasoning.â€  
   **Output:** â€œHola â€“ this is the common Spanish greeting used worldwide...â€

3. **Prompt:**  
   â€œStep-by-step, explain how â€˜Helloâ€™ translates into Spanish considering different dialects.â€  
   **Output:** Deeper, regional response.

> See how more structured or role-specific prompts lead to better and richer answers? Thatâ€™s prompt engineering in action.

---

## ğŸ”¹ 5. Wrap-Up 

### ğŸ”„ Recap:

- **Transformers:** The core technology that understands language using attention.
- **LLMs:** Scaled-up transformers trained on massive text corpora.
- **Prompt Engineering:** A technique to talk to LLMs effectively and creatively.

ğŸ’­ *In simple words: Transformers gave us the brain, LLMs gave us the language, and prompting is how we talk to them.*

## ğŸ–¼ï¸ Resources for reference 
1. [Prompt Engineering Guide â€“ Covers fundamentals, techniques, and best practices.](https://www.promptingguide.ai/)
2. [Prompt Engineering Tutorial â€“ A beginner-friendly guide with practical examples.](https://www.tutorialspoint.com/prompt_engineering/index.html)
3. [Basic Prompt Engineering â€“ Explains different prompting techniques with examples.](https://aiengineering.academy/PromptEngineering/Basic_Prompting/)

---

## ğŸ™Œ Acknowledgements

- **Organized by:** Global AI Secunderabad
- **Supported by:** DotNet Learners House Hyderabad  
- **Special thanks:** All participants and volunteers

---

## ğŸ”— Stay Connected

- [LinkedIn â€“ Yashasri Gudhe]( https://www.linkedin.com/in/sriya-kajjapu-919231325)
- [Global AI secunderabad](https://www.meetup.com/global-ai-secunderabad/)
- [Dot Net Learner House](https://www.meetup.com/dot-net-learners-house-hyderabad/)
- Contact: kajjapusriya@gmail.com

---
