# 🚀 Global AI Bootcamp – Prompt Engineering with LangChain

📅 **Date:** 14 June 2025  
🕙 **Time:** 10:00 AM IST  
📍 **Location:** Microsoft, Hyderabad   
🔗 **Event Link:** [Register on Meetup](https://www.meetup.com/dot-net-learners-house-hyderabad/events/308109558/?eventOrigin=group_events_list)

**Speaker:** Kajjapu Sriya  
**Topic:** **Introduction to LLMs and Prompt Engineering**  
🛠️ **Live Demo:** LangChain in Action!

 ![GAIS Banner](event banner.png) 

---

### Software/Tools

> 1. OS: Windows 10/11 x64
> 1. Python / .NET 8
> 1. Visual Studio 2022
> 1. Visual Studio Code

### Prior Knowledge

> 1. Programming knowledge in C# / Python

## Technology Stack

> 1. .NET 8, AI, Open AI

---

![Information | 100x100](../Information.png)

---

 ### What are we doing today?
1. Understanding Prompt Engineering
2. What is prompting and why it matters in AI.
3. How prompts guide reasoning and improve accuracy.
4. Real-world use cases with simple examples.

---

![Seatbelt| 100x100](../SeatBelt.png)

---

## 🧠 Session Overview

Prompting is the art of crafting clear instructions for AI models using natural language.  
It helps guide the model’s reasoning, improve accuracy, and ensure structured and relevant responses.

---

# 🎤 Introduction to LLMs & Prompt Engineering

---

## 🔹 1. Introduction

- **Transformers** are deep learning models that changed how machines understand human language by focusing on context and meaning through something called attention.
- **LLMs**—like GPT-4, Claude, or LLaMA—are AI systems built using transformers, trained on huge datasets, and capable of generating human-like language.
- **Prompt Engineering** is how we talk to these models to get the best results—like crafting the perfect question for the smartest assistant in the world

---

## 🔹 2. Transformers – The Backbone of AI

### 🧠 What is a Transformer?

In 2017, a paper called "*Attention is All You Need*" introduced the Transformer architecture, and it revolutionized NLP—Natural Language Processing.

**Why was it revolutionary?**
- RNNs and LSTMs, older models, processed sentences word-by-word. They were slow and forgot long-term context.
- **Transformers**, in contrast, process all words in parallel and decide what to ‘pay attention’ to.

---

### 🔍 Key Concepts

- **Self-Attention**

  > Example: In “The cat sat on the mat,” the word “sat” should focus more on “cat” than “mat.” Self-attention helps find that relationship.

- **Multi-Head Attention**

  > It’s like multiple minds looking at the same sentence from different angles.

- **Positional Encoding**

  > Since words are seen in parallel, we need to give the model a sense of order. That’s what positional encoding does—adds a rhythm or position to each word.

---

### 🎥 Demo Idea
- Highlight how in a sentence, different words relate with varying strengths.
- E.g., show attention weights between “sat” and “cat” vs “sat” and “the”.

> Transformers allow models to handle long texts and generate more coherent language. They’re the brains behind all modern LLMs.

---

## 🔹 3. Large Language Models (LLMs) – Language Generation Engines

### 💡 What is an LLM?

LLMs are transformers that have been trained on massive text data—books, websites, code, Wikipedia—to predict the next word in a sentence.

---

### 🧩 Key Ideas

- **Tokenization** – Breaks input into units (like words or subwords).
  
  > “ChatGPT is cool” → [“Chat”, “G”, “PT”, “is”, “cool”]

- **Next Word Prediction** – Given a sentence, what’s the most probable next word?
- **Fine-Tuning** – Pretrained models can be customized for tasks like legal advice, customer service, etc.

---

### 🎥 Live Demo Idea

1. Use GPT-4 or Azure OpenAI Studio.
2. Try:
    - “Write a haiku about space.”
    - “Explain black holes in 5-year-old language.”
    - “Help me debug a Python function.”

> Notice how the same model adapts its tone, language, and depth just based on your request. That’s the power of LLMs!

---

## 🔹 4. Prompt Engineering – Crafting Better Inputs

### 🛠️ What is Prompt Engineering?

It’s the art of asking questions the right way. The better the prompt, the better the response.

---

### 📌 Prompt Styles

- **Zero-shot Prompt**

  > “Translate ‘Hello’ to French.” → “Bonjour”

- **Few-shot Prompt**

  > Give examples:
  > 
  > English → French  
  > Hello → Bonjour  
  > Thank you → Merci  
  > Good night → ?

- **Chain-of-Thought Prompt**

  > “If Alice is taller than Bob, and Bob is taller than Carol, who’s tallest? Explain step by step.”

---

### 🎥 Demo (run three versions)

1. **Prompt:**  
   “Translate ‘Hello’ into Spanish.”  
   **Output:** “Hola”

2. **Prompt:**  
   “You are an expert translator. Translate ‘Hello’ into Spanish and explain your reasoning.”  
   **Output:** “Hola – this is the common Spanish greeting used worldwide...”

3. **Prompt:**  
   “Step-by-step, explain how ‘Hello’ translates into Spanish considering different dialects.”  
   **Output:** Deeper, regional response.

> See how more structured or role-specific prompts lead to better and richer answers? That’s prompt engineering in action.

---

## 🔹 5. Wrap-Up 

### 🔄 Recap:

- **Transformers:** The core technology that understands language using attention.
- **LLMs:** Scaled-up transformers trained on massive text corpora.
- **Prompt Engineering:** A technique to talk to LLMs effectively and creatively.

💭 *In simple words: Transformers gave us the brain, LLMs gave us the language, and prompting is how we talk to them.*

## 🖼️ Resources for reference 
1. [Prompt Engineering Guide – Covers fundamentals, techniques, and best practices.](https://www.promptingguide.ai/)
2. [Prompt Engineering Tutorial – A beginner-friendly guide with practical examples.](https://www.tutorialspoint.com/prompt_engineering/index.html)
3. [Basic Prompt Engineering – Explains different prompting techniques with examples.](https://aiengineering.academy/PromptEngineering/Basic_Prompting/)

---

## 🙌 Acknowledgements

- **Organized by:** Global AI Secunderabad
- **Supported by:** DotNet Learners House Hyderabad  
- **Special thanks:** All participants and volunteers

---

## 🔗 Stay Connected

- [LinkedIn – Yashasri Gudhe]( https://www.linkedin.com/in/sriya-kajjapu-919231325)
- [Global AI secunderabad](https://www.meetup.com/global-ai-secunderabad/)
- [Dot Net Learner House](https://www.meetup.com/dot-net-learners-house-hyderabad/)
- Contact: kajjapusriya@gmail.com

---
